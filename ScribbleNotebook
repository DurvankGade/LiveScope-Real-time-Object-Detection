{
  "metadata": {
    "name": "New JSNB",
    "language_info": {
      "name": "JavaScipt",
      "version": "8.0"
    }
  },
  "jsnbversion": "v0.1",
  "cells": [
    {
      "code": "<style>\n    body {\n            margin: 0;\n            height: 100vh;\n            display: flex;\n            flex-direction: column;\n            justify-content: center;\n            align-items: center;\n            background-image: \n                url('https://as1.ftcdn.net/v2/jpg/05/68/42/84/1000_F_568428476_UuKjs74nkS6nZoIa2cTVUjxrFhbTJ7a0.jpg'), /* Background image */\n                radial-gradient(circle, rgba(255, 255, 255, 0.1), rgba(0, 0, 0, 0.5)); /* Light overlay */\n            background-size: cover; /* Cover the entire viewport */\n            background-position: center; /* Center the image */\n            font-family: 'Courier New', Courier, monospace; /* Retro font */\n            color: #fff; /* Default text color */\n            text-align: center; /* Centering text */\n            position: relative; /* For layering */\n        }\n\n        h1 {\n            color: #ffcc00; /* Bright yellow */\n            text-shadow: 2px 2px 0 rgba(0, 0, 0, 0.5); /* Text shadow for depth */\n            margin: 10px 0; /* Margin for spacing */\n        }\n\n        h2 {\n            color: #ff6699; /* Bright pink */\n            text-shadow: 2px 2px 0 rgba(0, 0, 0, 0.5);\n            margin: 10px 0;\n        }\n\n        h3 {\n            color: #66ffcc; /* Light teal */\n            text-shadow: 2px 2px 0 rgba(0, 0, 0, 0.5);\n            margin: 10px 0;\n        }\n\n        h4 {\n            color: #ff9966; /* Light orange */\n            text-shadow: 2px 2px 0 rgba(0, 0, 0, 0.5);\n            margin: 10px 0;\n        }\n\n        h5 {\n            color: #cc99ff; /* Light purple */\n            text-shadow: 2px 2px 0 rgba(0, 0, 0, 0.5);\n            margin: 10px 0;\n        }\n\n        h6 {\n            color: #ffcc66; /* Light yellow-orange */\n            text-shadow: 2px 2px 0 rgba(0, 0, 0, 0.5);\n            margin: 10px 0;\n        }\n\n        p {\n            color: #ffffff; /* White for paragraphs */\n            margin: 10px 20px; /* Margin for spacing */\n            text-shadow: 1px 1px 0 rgba(0, 0, 0, 0.5); /* Slight shadow for paragraphs */\n        }\n\n        .wrapper {\n            display: flex;\n            overflow-x: auto; /* Allow horizontal scrolling */\n            padding: 20px;\n            position: relative; /* For overlay positioning */\n            z-index: 2; /* Ensure cards are above the overlay */\n        }\n\n        .item {\n            position: relative;\n            margin: 0 10px;\n            transition: transform 0.3s ease; /* Smooth transition for scaling */\n        }\n\n        .item img {\n            width: 300px; /* Fixed width for images */\n            border-radius: 10px; /* Rounded corners */\n            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.5); /* Shadow for depth */\n        }\n\n        .item:hover {\n            transform: scale(1.1); /* Scale up on hover */\n        }\n\n        /* Move adjacent items when one is hovered */\n        .item:hover ~ .item {\n            transform: translateX(20px); /* Push right */\n        }\n\n        .item:hover ~ .item:hover {\n            transform: translateX(0); /* Reset for hovered item */\n        }\n\n        .item:hover ~ .item:hover ~ .item {\n            transform: translateX(20px); /* Push right for next item */\n        }\n\n        .item:hover ~ .item:hover ~ .item:hover {\n            transform: translateX(0); /* Reset for hovered item */\n        }</style>\n<h1>LiveScope</h1>",
      "status": "",
      "output": "<style>\n    body {\n            margin: 0;\n            height: 100vh;\n            display: flex;\n            flex-direction: column;\n            justify-content: center;\n            align-items: center;\n            background-image: \n                url('https://as1.ftcdn.net/v2/jpg/05/68/42/84/1000_F_568428476_UuKjs74nkS6nZoIa2cTVUjxrFhbTJ7a0.jpg'), /* Background image */\n                radial-gradient(circle, rgba(255, 255, 255, 0.1), rgba(0, 0, 0, 0.5)); /* Light overlay */\n            background-size: cover; /* Cover the entire viewport */\n            background-position: center; /* Center the image */\n            font-family: 'Courier New', Courier, monospace; /* Retro font */\n            color: #fff; /* Default text color */\n            text-align: center; /* Centering text */\n            position: relative; /* For layering */\n        }\n\n        h1 {\n            color: #ffcc00; /* Bright yellow */\n            text-shadow: 2px 2px 0 rgba(0, 0, 0, 0.5); /* Text shadow for depth */\n            margin: 10px 0; /* Margin for spacing */\n        }\n\n        h2 {\n            color: #ff6699; /* Bright pink */\n            text-shadow: 2px 2px 0 rgba(0, 0, 0, 0.5);\n            margin: 10px 0;\n        }\n\n        h3 {\n            color: #66ffcc; /* Light teal */\n            text-shadow: 2px 2px 0 rgba(0, 0, 0, 0.5);\n            margin: 10px 0;\n        }\n\n        h4 {\n            color: #ff9966; /* Light orange */\n            text-shadow: 2px 2px 0 rgba(0, 0, 0, 0.5);\n            margin: 10px 0;\n        }\n\n        h5 {\n            color: #cc99ff; /* Light purple */\n            text-shadow: 2px 2px 0 rgba(0, 0, 0, 0.5);\n            margin: 10px 0;\n        }\n\n        h6 {\n            color: #ffcc66; /* Light yellow-orange */\n            text-shadow: 2px 2px 0 rgba(0, 0, 0, 0.5);\n            margin: 10px 0;\n        }\n\n        p {\n            color: #ffffff; /* White for paragraphs */\n            margin: 10px 20px; /* Margin for spacing */\n            text-shadow: 1px 1px 0 rgba(0, 0, 0, 0.5); /* Slight shadow for paragraphs */\n        }\n\n        .wrapper {\n            display: flex;\n            overflow-x: auto; /* Allow horizontal scrolling */\n            padding: 20px;\n            position: relative; /* For overlay positioning */\n            z-index: 2; /* Ensure cards are above the overlay */\n        }\n\n        .item {\n            position: relative;\n            margin: 0 10px;\n            transition: transform 0.3s ease; /* Smooth transition for scaling */\n        }\n\n        .item img {\n            width: 300px; /* Fixed width for images */\n            border-radius: 10px; /* Rounded corners */\n            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.5); /* Shadow for depth */\n        }\n\n        .item:hover {\n            transform: scale(1.1); /* Scale up on hover */\n        }\n\n        /* Move adjacent items when one is hovered */\n        .item:hover ~ .item {\n            transform: translateX(20px); /* Push right */\n        }\n\n        .item:hover ~ .item:hover {\n            transform: translateX(0); /* Reset for hovered item */\n        }\n\n        .item:hover ~ .item:hover ~ .item {\n            transform: translateX(20px); /* Push right for next item */\n        }\n\n        .item:hover ~ .item:hover ~ .item:hover {\n            transform: translateX(0); /* Reset for hovered item */\n        }</style>\n<h1>LiveScope</h1>",
      "type": ""
    },
    {
      "code": "<h5>Welcome to LiveScope, a cutting-edge project designed to perform real-time object detection and recognition using JavaScript and TensorFlow.js. This project leverages the power of machine learning to identify objects in videos, making it perfect for various applications like surveillance, autonomous vehicles, and more.<h5>",
      "status": "",
      "output": "<h5>Welcome to LiveScope, a cutting-edge project designed to perform real-time object detection and recognition using JavaScript and TensorFlow.js. This project leverages the power of machine learning to identify objects in videos, making it perfect for various applications like surveillance, autonomous vehicles, and more.</h5><h5></h5>",
      "type": "html"
    },
    {
      "code": "<h3>What we can do:</h3><h6>\n1.Real-Time Object Detection and Recognition using a video file<br>\n2.Attention Detection<br></h6>",
      "status": "",
      "output": "<h3>What we can do:</h3><h6>\n1.Real-Time Object Detection and Recognition using a video file<br>\n2.Attention Detection<br></h6>",
      "type": "html"
    },
    {
      "code": "<h3>1.Real-Time Object Detection and Recognition</h3>\n",
      "status": "",
      "output": "<h3>1.Real-Time Object Detection and Recognition</h3>\n",
      "type": "html"
    },
    {
      "code": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Object Detection with COCO-SSD</title>\n    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css\">\n    <style>\n        body {\n            display: flex;\n            flex-direction: column;\n            align-items: center;\n            font-family: Arial, sans-serif;\n            margin: 0;\n            padding: 0;\n        }\n\n        header {\n            background: #007bff;\n            color: white;\n            padding: 10px;\n            text-align: center;\n            width: 100%;\n        }\n\n        section {\n            margin: 20px;\n            max-width: 800px;\n            background: white;\n            border-radius: 8px;\n            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n            padding: 20px;\n        }\n\n        img {\n            border: 1px solid #ccc;\n            margin-bottom: 10px;\n            border-radius: 4px;\n        }\n\n        button {\n            padding: 10px 20px;\n            font-size: 16px;\n            background: #28a745;\n            border: none;\n            color: white;\n            cursor: pointer;\n            border-radius: 4px;\n            transition: background 0.3s;\n        }\n\n        footer {\n            margin-top: auto;\n            padding: 20px;\n            background: #007bff;\n            color: white;\n            text-align: center;\n            width: 100%;\n        }\n\n        .modal {\n            display: none;\n            position: fixed;\n            z-index: 1000;\n            left: 0;\n            top: 0;\n            width: 100%;\n            height: 100%;\n            background-color: rgba(0, 0, 0, 0.5);\n            justify-content: center;\n            align-items: center;\n        }\n\n        .modal-content {\n            background-color: white;\n            padding: 20px;\n            border-radius: 8px;\n            width: 400px;\n        }\n\n        .close {\n            cursor: pointer;\n            float: right;\n            color: #aaa;\n            font-size: 20px;\n        }\n    </style>\n</head>\n<body>\n    <header>\n        <h1>Object Detection using COCO-SSD</h1>\n    </header>\n\n    <section>\n        <h2>Application Overview</h2>\n        <p>This application leverages TensorFlow.js and the COCO-SSD model to detect and label objects in real-time.</p>\n        <button onclick=\"document.getElementById('modal').style.display='flex'\">How It Works <i class=\"fas fa-info-circle\"></i></button>\n    </section>\n\n    <section>\n        <h2>Demo Image</h2>\n        <a href=\"https://ibb.co/DG7Fc5N\">\n            <img src=\"https://i.ibb.co/hMJLzfC/Screenshot-2024-11-10-114333.png\" alt=\"Screenshot-2024-11-10-114333\" border=\"0\">\n        </a>\n       \n        <p id=\"waitingMessage\">Please wait while the model is loading...</p>\n    </section>\n\n    <footer>\n        <p>&copy; 2024 Object Detection App</p>\n    </footer>\n\n    <!-- Modal for Detailed Working Steps -->\n    <div id=\"modal\" class=\"modal\" onclick=\"this.style.display='none'\">\n        <div class=\"modal-content\" onclick=\"event.stopPropagation()\">\n            <span class=\"close\" onclick=\"document.getElementById('modal').style.display='none'\">&times;</span>\n            <h2>How This Application Works</h2>\n            <ol>\n                <li><strong>Setup:</strong> The application loads TensorFlow.js and COCO-SSD model scripts.</li>\n                <li><strong>Webcam Access:</strong> (Not applicable in this demo)</li>\n                <li><strong>Model Loading:</strong> The pre-trained COCO-SSD model is loaded for object recognition.</li>\n                <li><strong>Detection Process:</strong> The application is ready to detect objects in images.</li>\n                <li><strong>Real-Time Results:</strong> Detected objects can be outlined on images if a real-time feed were included.</li>\n            </ol>\n        </div>\n    </div>\n\n    <script>\n        // Note: Detection script is removed as webcam and detection aren't utilized in this version.\n    </script>\n</body>\n</html>",
      "status": "",
      "output": "\n\n\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Object Detection with COCO-SSD</title>\n    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css\">\n    <style>\n        body {\n            display: flex;\n            flex-direction: column;\n            align-items: center;\n            font-family: Arial, sans-serif;\n            margin: 0;\n            padding: 0;\n        }\n\n        header {\n            background: #007bff;\n            color: white;\n            padding: 10px;\n            text-align: center;\n            width: 100%;\n        }\n\n        section {\n            margin: 20px;\n            max-width: 800px;\n            background: white;\n            border-radius: 8px;\n            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n            padding: 20px;\n        }\n\n        img {\n            border: 1px solid #ccc;\n            margin-bottom: 10px;\n            border-radius: 4px;\n        }\n\n        button {\n            padding: 10px 20px;\n            font-size: 16px;\n            background: #28a745;\n            border: none;\n            color: white;\n            cursor: pointer;\n            border-radius: 4px;\n            transition: background 0.3s;\n        }\n\n        footer {\n            margin-top: auto;\n            padding: 20px;\n            background: #007bff;\n            color: white;\n            text-align: center;\n            width: 100%;\n        }\n\n        .modal {\n            display: none;\n            position: fixed;\n            z-index: 1000;\n            left: 0;\n            top: 0;\n            width: 100%;\n            height: 100%;\n            background-color: rgba(0, 0, 0, 0.5);\n            justify-content: center;\n            align-items: center;\n        }\n\n        .modal-content {\n            background-color: white;\n            padding: 20px;\n            border-radius: 8px;\n            width: 400px;\n        }\n\n        .close {\n            cursor: pointer;\n            float: right;\n            color: #aaa;\n            font-size: 20px;\n        }\n    </style>\n\n\n    <header>\n        <h1>Object Detection using COCO-SSD</h1>\n    </header>\n\n    <section>\n        <h2>Application Overview</h2>\n        <p>This application leverages TensorFlow.js and the COCO-SSD model to detect and label objects in real-time.</p>\n        <button onclick=\"document.getElementById('modal').style.display='flex'\">How It Works <i class=\"fas fa-info-circle\"></i></button>\n    </section>\n\n    <section>\n        <h2>Demo Image</h2>\n        <a href=\"https://ibb.co/DG7Fc5N\">\n            <img src=\"https://i.ibb.co/hMJLzfC/Screenshot-2024-11-10-114333.png\" alt=\"Screenshot-2024-11-10-114333\" border=\"0\">\n        </a>\n       \n        <p id=\"waitingMessage\">Please wait while the model is loading...</p>\n    </section>\n\n    <footer>\n        <p>� 2024 Object Detection App</p>\n    </footer>\n\n    <!-- Modal for Detailed Working Steps -->\n    <div id=\"modal\" class=\"modal\" onclick=\"this.style.display='none'\">\n        <div class=\"modal-content\" onclick=\"event.stopPropagation()\">\n            <span class=\"close\" onclick=\"document.getElementById('modal').style.display='none'\">�</span>\n            <h2>How This Application Works</h2>\n            <ol>\n                <li><strong>Setup:</strong> The application loads TensorFlow.js and COCO-SSD model scripts.</li>\n                <li><strong>Webcam Access:</strong> (Not applicable in this demo)</li>\n                <li><strong>Model Loading:</strong> The pre-trained COCO-SSD model is loaded for object recognition.</li>\n                <li><strong>Detection Process:</strong> The application is ready to detect objects in images.</li>\n                <li><strong>Real-Time Results:</strong> Detected objects can be outlined on images if a real-time feed were included.</li>\n            </ol>\n        </div>\n    </div>\n\n    <script>\n        // Note: Detection script is removed as webcam and detection aren't utilized in this version.\n    </script>\n\n",
      "type": "html"
    },
    {
      "code": "(async () => {\n    const container = document.createElement('div');\n    container.style.display = 'flex';\n    container.style.flexDirection = 'column';\n    container.style.alignItems = 'center';\n    document.body.appendChild(container);\n\n    const waitingMessage = document.createElement('p');\n    waitingMessage.innerText = 'Setting up... Please wait.';\n    container.appendChild(waitingMessage);\n\n    if(scrib.isSandboxed()) {\n        alert(\"Please take it out of sandbox by clicking the red button on top right corner\");\n        return;\n    }\n\n    const loadScript = (url) => {\n        return new Promise((resolve, reject) => {\n            const script = document.createElement('script');\n            script.src = url;\n            script.onload = resolve;\n            script.onerror = (e) => reject(new Error(`Failed to load script: ${url}`));\n            document.head.appendChild(script);\n        });\n    };\n\n    await loadScript('https://cdn.jsdelivr.net/npm/@tensorflow/tfjs').catch(console.error);\n    await loadScript('https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd').catch(console.error);\n\n    const video = document.createElement('video');\n    video.width = 640;\n    video.height = 480;\n    video.id = 'myVideo';\n    video.autoplay = true;\n    container.appendChild(video);\n\n    let stream;\n    navigator.mediaDevices.getUserMedia({ video: true })\n        .then((cameraStream) => {\n            stream = cameraStream;\n            video.srcObject = cameraStream;\n        })\n        .catch((error) => {\n            console.error('Error accessing camera:', error.message);\n        });\n\n    const model = await cocoSsd.load().catch(console.error);\n\n    const canvas = document.createElement('canvas');\n    canvas.width = video.width;\n    canvas.height = video.height;\n    canvas.id = 'canvas';\n    container.appendChild(canvas);\n    const ctx = canvas.getContext('2d');\n\n    waitingMessage.style.display = 'none';\n\n    const analyzeButton = document.createElement('button');\n    analyzeButton.innerText = 'Analyze';\n    container.insertBefore(analyzeButton, video);\n\n    const colorMap = {\n        'person': 'red', 'bicycle': 'blue', 'car': 'green', 'motorcycle': 'yellow', 'airplane': 'purple',\n        'bus': 'orange', 'train': 'pink', 'truck': 'brown', 'boat': 'cyan', 'traffic light': 'magenta',\n        'fire hydrant': 'lime', 'stop sign': 'indigo', 'parking meter': 'violet', 'bench': 'gold',\n        'bird': 'teal', 'cat': 'olive', 'dog': 'maroon', 'horse': 'navy', 'sheep': 'aqua', 'cow': 'lime',\n        'elephant': 'fuchsia', 'bear': 'salmon', 'zebra': 'khaki', 'giraffe': 'coral', 'backpack': 'orchid',\n        'umbrella': 'plum', 'handbag': 'silver', 'tie': 'lavender', 'suitcase': 'peachpuff', 'frisbee': 'hotpink',\n        'skis': 'firebrick', 'snowboard': 'crimson', 'sports ball': 'greenyellow', 'kite': 'turquoise',\n        'baseball bat': 'mediumslateblue', 'baseball glove': 'dodgerblue', 'skateboard': 'seashell', 'surfboard': 'tan',\n        'tennis racket': 'lightcoral', 'bottle': 'palegoldenrod', 'wine glass': 'tomato', 'cup': 'peru',\n        'fork': 'slateblue', 'knife': 'mediumvioletred', 'spoon': 'mediumspringgreen', 'bowl': 'midnightblue',\n        'banana': 'lightgreen', 'apple': 'sandybrown', 'sandwich': 'lemonchiffon', 'orange': 'chocolate',\n        'broccoli': 'springgreen', 'carrot': 'darkseagreen', 'hot dog': 'indianred', 'pizza': 'peru',\n        'donut': 'goldenrod', 'cake': 'mediumseagreen', 'chair': 'powderblue', 'couch': 'sienna', 'potted plant': 'coral',\n        'bed': 'forestgreen', 'dining table': 'steelblue', 'toilet': 'gainsboro', 'tv': 'burlywood', 'laptop': 'mistyrose',\n        'mouse': 'beige', 'remote': 'azure', 'keyboard': 'thistle', 'cell phone': 'gold', 'microwave': 'lightsteelblue',\n        'oven': 'chartreuse', 'toaster': 'blanchedalmond', 'sink': 'darkorchid', 'refrigerator': 'palegreen',\n        'book': 'darkgoldenrod', 'clock': 'lightskyblue', 'vase': 'darkblue', 'scissors': 'darkslateblue',\n        'teddy bear': 'saddlebrown', 'hair drier': 'limegreen', 'toothbrush': 'slategray'\n    };\n\n    async function detectObjects() {\n        if (video.readyState === 4) {\n            try {\n                const predictions = await model.detect(video);\n                ctx.clearRect(0, 0, canvas.width, canvas.height);\n                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n\n                predictions.forEach(prediction => {\n                    ctx.beginPath();\n                    ctx.rect(...prediction.bbox);\n                    ctx.lineWidth = 4;\n                    ctx.strokeStyle = colorMap[prediction.class] || 'red';\n                    ctx.fillStyle = colorMap[prediction.class] || 'red';\n                    ctx.stroke();\n                    ctx.font = '16px Arial';\n                    ctx.fillText(\n                        `${prediction.class} - ${Math.round(prediction.score * 100)}%`,\n                        prediction.bbox[0],\n                        prediction.bbox[1] > 20 ? prediction.bbox[1] - 10 : 20\n                    );\n                });\n            } catch (error) {\n                console.error(\"Detection error: \", error);\n            }\n        }\n        requestAnimationFrame(detectObjects);\n    }\n\n    analyzeButton.onclick = () => {\n        detectObjects();\n        console.log(\"Analyze button clicked, starting real-time detection\");\n    };\n})();\n\n",
      "status": "[2]<br><span style=\"font-size:8px\">3.319s<span></span></span>",
      "output": "",
      "type": "code"
    },
    {
      "code": "<h3>2.Attention Detection</h3>",
      "status": "",
      "output": "<h3>2.Attention Detection</h3>",
      "type": "html"
    },
    {
      "code": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Attention Detection Application</title>\n    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css\">\n    <style>\n        body {\n            font-family: Arial, sans-serif;\n           \n            margin: 0;\n            padding: 0;\n            display: flex;\n            flex-direction: column;\n            align-items: center;\n            color: #333;\n        }\n\n        header {\n            background: #007bff;\n            color: white;\n            width: 100%;\n            padding: 20px;\n            text-align: center;\n            position: relative;\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);\n        }\n\n        h1 {\n            margin: 0;\n            font-size: 2.5em;\n        }\n\n        section {\n            background: white;\n            margin: 20px;\n            max-width: 800px;\n            border-radius: 10px;\n            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);\n            overflow: hidden;\n            transition: transform 0.3s;\n            padding: 20px;\n        }\n\n        section:hover {\n            transform: translateY(-5px);\n        }\n\n        h2 {\n            font-size: 1.8em;\n            margin-bottom: 10px;\n            color: #007bff;\n            position: relative;\n        }\n\n        h2::after {\n            content: '';\n            position: absolute;\n            width: 50px;\n            height: 5px;\n            background: #007bff;\n            bottom: -5px;\n            left: 0;\n        }\n\n        p {\n            line-height: 1.6;\n            margin: 10px 0;\n        }\n\n        .steps {\n            list-style-type: none;\n            padding: 0;\n        }\n\n        .steps li {\n            background: #e9ecef;\n            margin: 10px 0;\n            padding: 15px;\n            border-radius: 8px;\n            position: relative;\n            transition: transform 0.2s;\n            cursor: pointer;\n        }\n\n        .steps li:hover {\n            transform: translateY(-2px);\n        }\n\n        .steps li:before {\n            content: counter(step);\n            counter-increment: step;\n            background: #28a745;\n            color: white;\n            border-radius: 50%;\n            width: 30px;\n            height: 30px;\n            display: flex;\n            align-items: center;\n            justify-content: center;\n            position: absolute;\n            left: -40px;\n            top: 15px;\n            font-weight: bold;\n        }\n\n        footer {\n            background: #007bff;\n            color: white;\n            padding: 20px;\n            text-align: center;\n            width: 100%;\n            margin-top: auto;\n        }\n\n        .demo-image {\n            display: flex;\n            justify-content: center;\n            margin: 20px 0;\n        }\n\n        .demo-image img {\n            max-width: 100%;\n            border-radius: 8px;\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);\n        }\n\n        @media screen and (max-width: 768px) {\n            h2 {\n                font-size: 1.5em;\n            }\n\n            section {\n                margin: 10px;\n                padding: 10px;\n            }\n        }\n    </style>\n</head>\n<body>\n\n<header>\n    <h1>Attention Detection Application</h1>\n</header>\n\n<section>\n    <h2>What is Attention Detection?</h2>\n    <p>\n        Attention Detection utilizes computer vision to monitor and assess an individual's attention level based on face\n        detection through the camera. This technology can be applied in various fields, from educational environments to\n        workplace productivity. This application leverages TensorFlow.js and BlazeFace model for real-time face\n        detection.\n    </p>\n</section>\n\n<section>\n    <h2>Steps to Implement Attention Detection</h2>\n    <ol class=\"steps\">\n        <li>Load the required TensorFlow.js and BlazeFace scripts.</li>\n        <li>Create a video element to stream the user's webcam.</li>\n        <li>Set up a canvas element to overlay face detection results.</li>\n        <li>Initialize the webcam stream and present it to the video element.</li>\n        <li>Load the BlazeFace model for face detection capabilities.</li>\n        <li>In a loop, detect faces from the video stream, drawing overlays on the canvas.</li>\n        <li>Evaluate if the detected face indicates high attention based on position and size.</li>\n    </ol>\n</section>\n\n<section>\n    <h2>Applications of Attention Detection</h2>\n    <p>\n        Attention Detection can be useful in various scenarios:\n    </p>\n    <ul>\n        <li><strong>Education:</strong> Track students' focus during online learning sessions.</li>\n        <li><strong>Meetings:</strong> Assess engagement levels in virtual meetings.</li>\n        <li><strong>Safety:</strong> Monitor driver attentiveness in transportation.</li>\n        <li><strong>Marketing:</strong> Evaluate consumer attention towards advertisements.</li>\n    </ul>\n\n    <div class=\"demo-image\">\n        <a href=\"https://ibb.co/GHXHKzt\">\n            <img src=\"https://i.ibb.co/MBbBYFG/Screenshot-2024-11-10-125957.png\" alt=\"Attention Detection Demo\" border=\"0\">\n        </a>\n    </div>\n</section>\n\n<footer>\n    <p>&copy; 2024 Attention Detection App</p>\n</footer>\n\n<script>\n    (async () => {\n        await loadScript('https://cdn.jsdelivr.net/npm/@tensorflow/tfjs');\n        await loadScript('https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface');\n\n        function loadScript(url) {\n            return new Promise((resolve, reject) => {\n                const script = document.createElement('script');\n                script.src = url;\n                script.onload = resolve;\n                script.onerror = reject;\n                document.head.appendChild(script);\n            });\n        }\n\n        const body = document.body;\n\n        const video = document.createElement('video');\n        video.id = 'video';\n        video.width = 640;\n        video.height = 480;\n        video.autoplay = true;\n        body.appendChild(video);\n\n        const canvas = document.createElement('canvas');\n        canvas.id = 'overlay';\n        canvas.width = 640;\n        canvas.height = 480;\n        canvas.style.position = 'absolute';\n        canvas.style.top = '0';\n        canvas.style.left = '0';\n        body.appendChild(canvas);\n\n        const attentionStatus = document.createElement('p');\n        attentionStatus.id = 'status';\n        attentionStatus.textContent = 'Attention Status: Unknown';\n        body.appendChild(attentionStatus);\n\n        const videoElement = document.getElementById('video');\n        const canvasElement = document.getElementById('overlay');\n        const statusElement = document.getElementById('status');\n        const ctx = canvasElement.getContext('2d');\n\n        try {\n            const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n            videoElement.srcObject = stream;\n        } catch (error) {\n            console.error('Error accessing camera:', error);\n            alert('Error accessing camera. Please ensure you have allowed permissions.');\n            return;\n        }\n\n        const model = await blazeface.load();\n\n        async function detectAttention() {\n            const returnTensors = false;\n            const predictions = await model.estimateFaces(videoElement, returnTensors);\n\n            ctx.clearRect(0, 0, canvasElement.width, canvasElement.height);\n\n            if (predictions.length > 0) {\n                predictions.forEach(prediction => {\n                    const start = prediction.topLeft;\n                    const end = prediction.bottomRight;\n                    const size = [end[0] - start[0], end[1] - start[1]];\n\n                    ctx.fillStyle = 'rgba(0, 255, 0, 0.5)';\n                    ctx.fillRect(start[0], start[1], size[0], size[1]);\n\n                    const headCenterX = (start[0] + end[0]) / 2;\n                    const headCenterY = (start[1] + end[1]) / 2;\n                    const faceWidth = end[0] - start[0];\n\n                    if (headCenterX > canvasElement.width * 0.35 && headCenterX < canvasElement.width * 0.65 && faceWidth > canvasElement.width * 0.2) {\n                        statusElement.textContent = 'Attention Status: Paying Attention';\n                    } else {\n                        statusElement.textContent = 'Attention Status: Not Paying Attention';\n                    }\n                });\n            } else {\n                statusElement.textContent = 'Attention Status: No Face Detected';\n            }\n            requestAnimationFrame(detectAttention);\n        }\n\n        detectAttention();\n    })();\n</script>\n\n</body>\n</html>",
      "status": "",
      "output": "\n\n\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Attention Detection Application</title>\n    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css\">\n    <style>\n        body {\n            font-family: Arial, sans-serif;\n           \n            margin: 0;\n            padding: 0;\n            display: flex;\n            flex-direction: column;\n            align-items: center;\n            color: #333;\n        }\n\n        header {\n            background: #007bff;\n            color: white;\n            width: 100%;\n            padding: 20px;\n            text-align: center;\n            position: relative;\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);\n        }\n\n        h1 {\n            margin: 0;\n            font-size: 2.5em;\n        }\n\n        section {\n            background: white;\n            margin: 20px;\n            max-width: 800px;\n            border-radius: 10px;\n            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);\n            overflow: hidden;\n            transition: transform 0.3s;\n            padding: 20px;\n        }\n\n        section:hover {\n            transform: translateY(-5px);\n        }\n\n        h2 {\n            font-size: 1.8em;\n            margin-bottom: 10px;\n            color: #007bff;\n            position: relative;\n        }\n\n        h2::after {\n            content: '';\n            position: absolute;\n            width: 50px;\n            height: 5px;\n            background: #007bff;\n            bottom: -5px;\n            left: 0;\n        }\n\n        p {\n            line-height: 1.6;\n            margin: 10px 0;\n        }\n\n        .steps {\n            list-style-type: none;\n            padding: 0;\n        }\n\n        .steps li {\n            background: #e9ecef;\n            margin: 10px 0;\n            padding: 15px;\n            border-radius: 8px;\n            position: relative;\n            transition: transform 0.2s;\n            cursor: pointer;\n        }\n\n        .steps li:hover {\n            transform: translateY(-2px);\n        }\n\n        .steps li:before {\n            content: counter(step);\n            counter-increment: step;\n            background: #28a745;\n            color: white;\n            border-radius: 50%;\n            width: 30px;\n            height: 30px;\n            display: flex;\n            align-items: center;\n            justify-content: center;\n            position: absolute;\n            left: -40px;\n            top: 15px;\n            font-weight: bold;\n        }\n\n        footer {\n            background: #007bff;\n            color: white;\n            padding: 20px;\n            text-align: center;\n            width: 100%;\n            margin-top: auto;\n        }\n\n        .demo-image {\n            display: flex;\n            justify-content: center;\n            margin: 20px 0;\n        }\n\n        .demo-image img {\n            max-width: 100%;\n            border-radius: 8px;\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);\n        }\n\n        @media screen and (max-width: 768px) {\n            h2 {\n                font-size: 1.5em;\n            }\n\n            section {\n                margin: 10px;\n                padding: 10px;\n            }\n        }\n    </style>\n\n\n\n<header>\n    <h1>Attention Detection Application</h1>\n</header>\n\n<section>\n    <h2>What is Attention Detection?</h2>\n    <p>\n        Attention Detection utilizes computer vision to monitor and assess an individual's attention level based on face\n        detection through the camera. This technology can be applied in various fields, from educational environments to\n        workplace productivity. This application leverages TensorFlow.js and BlazeFace model for real-time face\n        detection.\n    </p>\n</section>\n\n<section>\n    <h2>Steps to Implement Attention Detection</h2>\n    <ol class=\"steps\">\n        <li>Load the required TensorFlow.js and BlazeFace scripts.</li>\n        <li>Create a video element to stream the user's webcam.</li>\n        <li>Set up a canvas element to overlay face detection results.</li>\n        <li>Initialize the webcam stream and present it to the video element.</li>\n        <li>Load the BlazeFace model for face detection capabilities.</li>\n        <li>In a loop, detect faces from the video stream, drawing overlays on the canvas.</li>\n        <li>Evaluate if the detected face indicates high attention based on position and size.</li>\n    </ol>\n</section>\n\n<section>\n    <h2>Applications of Attention Detection</h2>\n    <p>\n        Attention Detection can be useful in various scenarios:\n    </p>\n    <ul>\n        <li><strong>Education:</strong> Track students' focus during online learning sessions.</li>\n        <li><strong>Meetings:</strong> Assess engagement levels in virtual meetings.</li>\n        <li><strong>Safety:</strong> Monitor driver attentiveness in transportation.</li>\n        <li><strong>Marketing:</strong> Evaluate consumer attention towards advertisements.</li>\n    </ul>\n\n    <div class=\"demo-image\">\n        <a href=\"https://ibb.co/GHXHKzt\">\n            <img src=\"https://i.ibb.co/MBbBYFG/Screenshot-2024-11-10-125957.png\" alt=\"Attention Detection Demo\" border=\"0\">\n        </a>\n    </div>\n</section>\n\n<footer>\n    <p>� 2024 Attention Detection App</p>\n</footer>\n\n<script>\n    (async () => {\n        await loadScript('https://cdn.jsdelivr.net/npm/@tensorflow/tfjs');\n        await loadScript('https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface');\n\n        function loadScript(url) {\n            return new Promise((resolve, reject) => {\n                const script = document.createElement('script');\n                script.src = url;\n                script.onload = resolve;\n                script.onerror = reject;\n                document.head.appendChild(script);\n            });\n        }\n\n        const body = document.body;\n\n        const video = document.createElement('video');\n        video.id = 'video';\n        video.width = 640;\n        video.height = 480;\n        video.autoplay = true;\n        body.appendChild(video);\n\n        const canvas = document.createElement('canvas');\n        canvas.id = 'overlay';\n        canvas.width = 640;\n        canvas.height = 480;\n        canvas.style.position = 'absolute';\n        canvas.style.top = '0';\n        canvas.style.left = '0';\n        body.appendChild(canvas);\n\n        const attentionStatus = document.createElement('p');\n        attentionStatus.id = 'status';\n        attentionStatus.textContent = 'Attention Status: Unknown';\n        body.appendChild(attentionStatus);\n\n        const videoElement = document.getElementById('video');\n        const canvasElement = document.getElementById('overlay');\n        const statusElement = document.getElementById('status');\n        const ctx = canvasElement.getContext('2d');\n\n        try {\n            const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n            videoElement.srcObject = stream;\n        } catch (error) {\n            console.error('Error accessing camera:', error);\n            alert('Error accessing camera. Please ensure you have allowed permissions.');\n            return;\n        }\n\n        const model = await blazeface.load();\n\n        async function detectAttention() {\n            const returnTensors = false;\n            const predictions = await model.estimateFaces(videoElement, returnTensors);\n\n            ctx.clearRect(0, 0, canvasElement.width, canvasElement.height);\n\n            if (predictions.length > 0) {\n                predictions.forEach(prediction => {\n                    const start = prediction.topLeft;\n                    const end = prediction.bottomRight;\n                    const size = [end[0] - start[0], end[1] - start[1]];\n\n                    ctx.fillStyle = 'rgba(0, 255, 0, 0.5)';\n                    ctx.fillRect(start[0], start[1], size[0], size[1]);\n\n                    const headCenterX = (start[0] + end[0]) / 2;\n                    const headCenterY = (start[1] + end[1]) / 2;\n                    const faceWidth = end[0] - start[0];\n\n                    if (headCenterX > canvasElement.width * 0.35 && headCenterX < canvasElement.width * 0.65 && faceWidth > canvasElement.width * 0.2) {\n                        statusElement.textContent = 'Attention Status: Paying Attention';\n                    } else {\n                        statusElement.textContent = 'Attention Status: Not Paying Attention';\n                    }\n                });\n            } else {\n                statusElement.textContent = 'Attention Status: No Face Detected';\n            }\n            requestAnimationFrame(detectAttention);\n        }\n\n        detectAttention();\n    })();\n</script>\n\n\n",
      "type": "html"
    },
    {
      "code": "(async () => {\n    await loadScript('https://cdn.jsdelivr.net/npm/@tensorflow/tfjs');\n    await loadScript('https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface');\n\n    function loadScript(url) {\n        return new Promise((resolve, reject) => {\n            const script = document.createElement('script');\n            script.src = url;\n            script.onload = resolve;\n            script.onerror = reject;\n            document.head.appendChild(script);\n        });\n    }\n\n    const body = document.body;\n\n    const h1 = document.createElement('h1');\n    h1.textContent = 'Attention Detection';\n    body.appendChild(h1);\n\n    const video = document.createElement('video');\n    video.id = 'video';\n    video.width = 640;\n    video.height = 480;\n    video.autoplay = true;\n    body.appendChild(video);\n\n    const canvas = document.createElement('canvas');\n    canvas.id = 'overlay';\n    canvas.width = 640;\n    canvas.height = 480;\n    canvas.style.position = 'absolute';\n    canvas.style.top = '0';\n    canvas.style.left = '0';\n    body.appendChild(canvas);\n\n    const attentionStatus = document.createElement('p');\n    attentionStatus.id = 'status';\n    attentionStatus.textContent = 'Attention Status: Unknown';\n    body.appendChild(attentionStatus);\n\n    const videoElement = document.getElementById('video');\n    const canvasElement = document.getElementById('overlay');\n    const statusElement = document.getElementById('status');\n    const ctx = canvasElement.getContext('2d');\n\n    try {\n        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n        videoElement.srcObject = stream;\n    } catch (error) {\n        console.error('Error accessing camera:', error);\n        alert('Error accessing camera. Please ensure you have allowed permissions.');\n        return;\n    }\n\n    const model = await blazeface.load();\n\n    async function detectAttention() {\n        const returnTensors = false;\n        const predictions = await model.estimateFaces(videoElement, returnTensors);\n\n        ctx.clearRect(0, 0, canvasElement.width, canvasElement.height);\n\n        if (predictions.length > 0) {\n            predictions.forEach(prediction => {\n                const start = prediction.topLeft;\n                const end = prediction.bottomRight;\n                const size = [end[0] - start[0], end[1] - start[1]];\n\n                ctx.fillStyle = 'rgba(0, 255, 0, 0.5)';\n                ctx.fillRect(start[0], start[1], size[0], size[1]);\n\n                const headCenterX = (start[0] + end[0]) / 2;\n                const headCenterY = (start[1] + end[1]) / 2;\n                const faceWidth = end[0] - start[0];\n\n                if (headCenterX > canvasElement.width * 0.35 && headCenterX < canvasElement.width * 0.65 && faceWidth > canvasElement.width * 0.2) {\n                    statusElement.textContent = 'Attention Status: Paying Attention';\n                } else {\n                    statusElement.textContent = 'Attention Status: Not Paying Attention';\n                }\n            });\n        } else {\n            statusElement.textContent = 'Attention Status: No Face Detected';\n        }\n        requestAnimationFrame(detectAttention);\n    }\n\n    detectAttention();\n})();\n",
      "status": "[1]<br><span style=\"font-size:8px\">5.489s<span></span></span>",
      "output": "",
      "type": "code"
    },
    {
      "code": "<h3>PDF to Quiz Generator</h3>",
      "status": "",
      "output": "<h3>PDF to Quiz Generator</h3>",
      "type": "html"
    },
    {
      "code": "(async () => {\n    await loadScript('https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.10.377/pdf.min.js');\n    await loadScript('https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css');\n    await loadScript('https://cdn.tailwindcss.com');\n\n    function loadScript(url) {\n        return new Promise((resolve, reject) => {\n            if (url.endsWith('.css')) {\n                const link = document.createElement('link');\n                link.rel = 'stylesheet';\n                link.href = url;\n                link.onload = resolve;\n                link.onerror = reject;\n                document.head.appendChild(link);\n            } else {\n                const script = document.createElement('script');\n                script.src = url;\n                script.onload = resolve;\n                script.onerror = reject;\n                document.head.appendChild(script);\n            }\n        });\n    }\n\n    const container = document.createElement('div');\n    container.className = 'min-h-screen bg-gradient-to-br from-indigo-600 via-purple-600 to-pink-600 p-8';\n    document.body.appendChild(container);\n\n    const appWrapper = document.createElement('div');\n    appWrapper.className = 'max-w-4xl mx-auto bg-white rounded-xl shadow-2xl p-6 animate__animated animate__fadeIn';\n    container.appendChild(appWrapper);\n\n    const header = document.createElement('div');\n    header.className = 'text-center mb-8';\n    header.innerHTML = `\n        <div class=\"animate__animated animate__bounceIn\">\n            <h1 class=\"text-5xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-indigo-600 to-pink-600 mb-4\">\n                Smart Quiz Creator\n            </h1>\n            <p class=\"text-gray-600 text-lg\">Transform any PDF into an interactive learning experience</p>\n        </div>\n    `;\n    appWrapper.appendChild(header);\n\n    const uploadSection = document.createElement('div');\n    uploadSection.className = 'mb-8 text-center';\n    uploadSection.innerHTML = `\n        <div class=\"flex items-center justify-center w-full\">\n            <label class=\"flex flex-col items-center justify-center w-full h-64 border-2 border-dashed rounded-2xl cursor-pointer bg-gradient-to-br from-gray-50 to-gray-100 hover:from-gray-100 hover:to-gray-200 transition-all duration-300\">\n                <div class=\"flex flex-col items-center justify-center pt-5 pb-6 px-4\">\n                    <div class=\"mb-3 text-indigo-600 animate__animated animate__pulse animate__infinite\">\n                        <svg class=\"w-12 h-12\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                            <path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12\"></path>\n                        </svg>\n                    </div>\n                    <p class=\"mb-2 text-lg text-gray-700\"><span class=\"font-semibold\">Click to upload</span> or drag and drop</p>\n                    <p class=\"text-sm text-gray-500\">PDF files only</p>\n                </div>\n                <input id=\"fileInput\" type=\"file\" class=\"hidden\" accept=\"application/pdf\" />\n            </label>\n        </div>\n    `;\n    appWrapper.appendChild(uploadSection);\n\n    const settingsSection = document.createElement('div');\n    settingsSection.className = 'mb-8 grid grid-cols-1 md:grid-cols-3 gap-4';\n    settingsSection.innerHTML = `\n        <div class=\"p-6 bg-gradient-to-br from-gray-50 to-gray-100 rounded-xl shadow-md\">\n            <label class=\"block text-sm font-medium text-gray-700 mb-3\">Number of Questions</label>\n            <input type=\"range\" id=\"questionCount\" min=\"5\" max=\"20\" value=\"10\" class=\"w-full accent-indigo-600\">\n            <div class=\"text-center text-sm text-gray-600 mt-2\"><span id=\"questionCountValue\">10</span> questions</div>\n        </div>\n        <div class=\"p-6 bg-gradient-to-br from-gray-50 to-gray-100 rounded-xl shadow-md\">\n            <label class=\"block text-sm font-medium text-gray-700 mb-3\">Time Limit (minutes)</label>\n            <input type=\"range\" id=\"timeLimit\" min=\"1\" max=\"10\" value=\"2\" step=\"1\" class=\"w-full accent-indigo-600\">\n            <div class=\"text-center text-sm text-gray-600 mt-2\"><span id=\"timeLimitValue\">2</span> minutes</div>\n        </div>\n        <div class=\"p-6 bg-gradient-to-br from-gray-50 to-gray-100 rounded-xl shadow-md\">\n            <label class=\"block text-sm font-medium text-gray-700 mb-3\">Difficulty Level</label>\n            <select id=\"difficulty\" class=\"w-full p-2 border rounded-lg focus:ring-2 focus:ring-indigo-500\">\n                <option value=\"easy\">Easy</option>\n                <option value=\"medium\" selected>Medium</option>\n                <option value=\"hard\">Hard</option>\n            </select>\n        </div>\n    `;\n    appWrapper.appendChild(settingsSection);\n\n    const progressBar = document.createElement('div');\n    progressBar.className = 'hidden mb-8';\n    progressBar.innerHTML = `\n        <div class=\"w-full bg-gray-200 rounded-full h-3\">\n            <div id=\"progressFill\" class=\"bg-gradient-to-r from-indigo-600 to-pink-600 h-3 rounded-full transition-all duration-300\" style=\"width: 0%\"></div>\n        </div>\n        <div id=\"timer\" class=\"text-center mt-3 text-lg font-medium text-gray-700\"></div>\n    `;\n    appWrapper.appendChild(progressBar);\n\n    const buttonSection = document.createElement('div');\n    buttonSection.className = 'flex justify-center gap-4 mb-8';\n    buttonSection.innerHTML = `\n        <button id=\"generateBtn\" class=\"px-8 py-4 bg-gradient-to-r from-indigo-600 to-purple-600 text-white rounded-xl shadow-lg hover:shadow-xl transform hover:-translate-y-0.5 transition-all duration-300 text-lg font-semibold disabled:opacity-50 disabled:cursor-not-allowed\">\n            Generate Quiz\n        </button>\n    `;\n    appWrapper.appendChild(buttonSection);\n\n    const quizContainer = document.createElement('div');\n    quizContainer.id = 'quiz';\n    quizContainer.className = 'space-y-6';\n    appWrapper.appendChild(quizContainer);\n\n    const resultsContainer = document.createElement('div');\n    resultsContainer.id = 'results';\n    resultsContainer.className = 'mt-8 hidden';\n    appWrapper.appendChild(resultsContainer);\n\n    const fileInput = document.getElementById('fileInput');\n    const generateBtn = document.getElementById('generateBtn');\n    const questionCountInput = document.getElementById('questionCount');\n    const timeLimitInput = document.getElementById('timeLimit');\n    const questionCountValue = document.getElementById('questionCountValue');\n    const timeLimitValue = document.getElementById('timeLimitValue');\n    const difficultySelect = document.getElementById('difficulty');\n\n    questionCountInput.addEventListener('input', () => {\n        questionCountValue.textContent = questionCountInput.value;\n    });\n\n    timeLimitInput.addEventListener('input', () => {\n        timeLimitValue.textContent = timeLimitInput.value;\n    });\n\n    function shuffleArray(array) {\n        for (let i = array.length - 1; i > 0; i--) {\n            const j = Math.floor(Math.random() * (i + 1));\n            [array[i], array[j]] = [array[j], array[i]];\n        }\n        return array;\n    }\n\n    async function extractTextAndGenerateQuiz(arrayBuffer) {\n        const loadingTask = pdfjsLib.getDocument({ data: arrayBuffer });\n        const pdf = await loadingTask.promise;\n        let extractedText = '';\n\n        for (let i = 1; i <= pdf.numPages; i++) {\n            const page = await pdf.getPage(i);\n            const textContent = await page.getTextContent();\n            const pageText = textContent.items.map(item => item.str).join(' ');\n            extractedText += ` ${pageText}`;\n            document.getElementById('progressFill').style.width = `${(i / pdf.numPages) * 100}%`;\n        }\n\n        return generateQuizQuestions(extractedText);\n    }\n\n    function generateQuizQuestions(text) {\n        const difficulty = difficultySelect.value;\n        const minLength = difficulty === 'easy' ? 20 : difficulty === 'medium' ? 30 : 40;\n        const sentences = text.split('. ').filter(sentence => sentence.trim().length > minLength);\n        const questionCount = parseInt(questionCountInput.value);\n        \n        return sentences.slice(0, questionCount).map((sentence, index) => {\n            const options = new Set();\n            options.add(sentence);\n\n            while (options.size < 4) {\n                const randomSentence = sentences[Math.floor(Math.random() * sentences.length)];\n                if (randomSentence.length > minLength) {\n                    options.add(randomSentence);\n                }\n            }\n\n            return {\n                question: `Question ${index + 1}: Which statement is correct?`,\n                options: shuffleArray(Array.from(options)),\n                correctAnswer: sentence\n            };\n        });\n    }\n\n    function displayQuiz(questions) {\n        const quizDiv = document.getElementById('quiz');\n        quizDiv.innerHTML = '';\n        \n        if (questions.length === 0) {\n            quizDiv.innerHTML = '<p class=\"text-center text-gray-600 text-lg\">No valid questions could be generated. Please try a different PDF.</p>';\n            return;\n        }\n\n        let timeLeft = parseInt(timeLimitInput.value) * 60;\n        const timerDisplay = document.getElementById('timer');\n\n        const updateTimer = () => {\n            const minutes = Math.floor(timeLeft / 60);\n            const seconds = timeLeft % 60;\n            timerDisplay.textContent = `Time remaining: ${minutes}:${seconds.toString().padStart(2, '0')}`;\n        };\n\n        updateTimer();\n\n        const timer = setInterval(() => {\n            timeLeft--;\n            updateTimer();\n            document.getElementById('progressFill').style.width = `${(timeLeft / (parseInt(timeLimitInput.value) * 60)) * 100}%`;\n\n            if (timeLeft <= 0) {\n                clearInterval(timer);\n                submitQuiz();\n            }\n        }, 1000);\n\n        questions.forEach((q, index) => {\n            const questionDiv = document.createElement('div');\n            questionDiv.className = 'bg-gradient-to-br from-gray-50 to-gray-100 rounded-xl p-6 shadow-md transform hover:scale-102 transition-all duration-300 animate__animated animate__fadeIn';\n            questionDiv.innerHTML = `\n                <p class=\"text-xl font-medium text-gray-900 mb-4\">${q.question}</p>\n                <div class=\"space-y-3\">\n                    ${q.options.map((option, optionIndex) => `\n                        <div class=\"flex items-center p-3 bg-white rounded-lg hover:bg-gray-50 transition-colors duration-200\">\n                            <input type=\"radio\" id=\"q${index}_${optionIndex}\" name=\"q${index}\" value=\"${option === q.correctAnswer}\" class=\"mr-3\">\n                            <label for=\"q${index}_${optionIndex}\" class=\"text-gray-700 cursor-pointer flex-1\">${option}</label>\n                        </div>\n                    `).join('')}\n                </div>\n            `;\n            quizDiv.appendChild(questionDiv);\n        });\n\n        const submitBtnContainer = document.createElement('div');\n        submitBtnContainer.className = 'fixed bottom-8 left-0 w-full flex justify-center';\n        submitBtnContainer.innerHTML = `\n            <button id=\"submitBtn\" class=\"px-8 py-4 bg-gradient-to-r from-green-600 to-teal-600 text-white rounded-xl shadow-lg hover:shadow-xl transform hover:-translate-y-0.5 transition-all duration-300 text-lg font-semibold\">\n                Submit Quiz\n            </button>\n        `;\n        document.body.appendChild(submitBtnContainer);\n\n        const submitBtn = document.getElementById('submitBtn');\n        submitBtn.addEventListener('click', () => submitQuiz());\n\n        function submitQuiz() {\n            clearInterval(timer);\n            let correctCount = 0;\n            const questionDivs = quizDiv.querySelectorAll('.bg-gradient-to-br');\n            submitBtn.remove();\n\n            questionDivs.forEach((questionDiv, index) => {\n                const selectedOption = questionDiv.querySelector('input[type=\"radio\"]:checked');\n                const resultDiv = document.createElement('div');\n                resultDiv.className = 'mt-4 p-4 rounded-lg animate__animated animate__fadeIn';\n\n                if (selectedOption) {\n                    const isCorrect = selectedOption.value === 'true';\n                    resultDiv.className += isCorrect ? ' bg-green-100' : ' bg-red-100';\n                    resultDiv.innerHTML = `\n                        <p class=\"font-medium ${isCorrect ? 'text-green-800' : 'text-red-800'}\">\n                            ${isCorrect ? '✓ Correct!' : '✗ Incorrect'}\n                        </p>\n                    `;\n                    if (isCorrect) correctCount++;\n                } else {\n                    resultDiv.className += ' bg-gray-100';\n                    resultDiv.innerHTML = '<p class=\"text-gray-800\">No answer selected</p>';\n                }\n                questionDiv.appendChild(resultDiv);\n            });\n\n            resultsContainer.className = resultsContainer.className.replace('hidden', '');\n            const score = Math.round((correctCount / questions.length) * 100);\n            resultsContainer.innerHTML = `\n                <div class=\"text-center p-8 bg-gradient-to-r from-indigo-100 to-purple-100 rounded-xl shadow-lg animate__animated animate__bounceIn\">\n                    <h2 class=\"text-3xl font-bold text-gray-900 mb-4\">Quiz Results</h2>\n                    <div class=\"flex justify-center items-center space-x-4 mb-4\">\n                        <div class=\"text-4xl font-bold ${score >= 70 ? 'text-green-600' : score >= 40 ? 'text-yellow-600' : 'text-red-600'}\">\n                            ${score}%\n                        </div>\n                        <div class=\"text-lg text-gray-700\">\n                            ${correctCount} out of ${questions.length} correct\n\t\t\t\t\t\t\t</div>\n                    </div>\n                    <div class=\"mb-6\">\n                        <div class=\"relative w-48 h-48 mx-auto\">\n                            <svg class=\"transform -rotate-90\" viewBox=\"0 0 100 100\">\n                                <circle class=\"text-gray-200\" stroke-width=\"10\" stroke=\"currentColor\" fill=\"transparent\" r=\"45\" cx=\"50\" cy=\"50\"/>\n                                <circle class=\"text-indigo-600\" stroke-width=\"10\" stroke=\"currentColor\" fill=\"transparent\" r=\"45\" cx=\"50\" cy=\"50\"\n                                    stroke-dasharray=\"${2 * Math.PI * 45}\"\n                                    stroke-dashoffset=\"${2 * Math.PI * 45 * (1 - score / 100)}\"/>\n                            </svg>\n                        </div>\n                    </div>\n                    <div class=\"text-lg text-gray-700 mb-6\">\n                        ${score >= 70 ? 'Excellent work! 🎉' : score >= 40 ? 'Good effort! 👍' : 'Keep practicing! 💪'}\n                    </div>\n                    <div class=\"flex justify-center space-x-4\">\n                        <button onclick=\"location.reload()\" class=\"px-6 py-3 bg-gradient-to-r from-indigo-600 to-purple-600 text-white rounded-lg shadow-md hover:shadow-lg transform hover:-translate-y-0.5 transition-all duration-300\">\n                            Try Another Quiz\n                        </button>\n                        <button onclick=\"window.print()\" class=\"px-6 py-3 bg-gradient-to-r from-gray-600 to-gray-700 text-white rounded-lg shadow-md hover:shadow-lg transform hover:-translate-y-0.5 transition-all duration-300\">\n                            Print Results\n                        </button>\n                    </div>\n                </div>\n                <div class=\"mt-8 p-6 bg-white rounded-xl shadow-md\">\n                    <h3 class=\"text-xl font-semibold text-gray-900 mb-4\">Performance Analysis</h3>\n                    <div class=\"grid grid-cols-1 md:grid-cols-3 gap-4\">\n                        <div class=\"p-4 bg-gradient-to-br from-indigo-50 to-indigo-100 rounded-lg\">\n                            <p class=\"text-sm text-gray-600\">Accuracy Rate</p>\n                            <p class=\"text-2xl font-bold text-indigo-600\">${score}%</p>\n                        </div>\n                        <div class=\"p-4 bg-gradient-to-br from-purple-50 to-purple-100 rounded-lg\">\n                            <p class=\"text-sm text-gray-600\">Time Spent</p>\n                            <p class=\"text-2xl font-bold text-purple-600\">${Math.round((parseInt(timeLimitInput.value) * 60 - timeLeft) / 60)} min</p>\n                        </div>\n                        <div class=\"p-4 bg-gradient-to-br from-pink-50 to-pink-100 rounded-lg\">\n                            <p class=\"text-sm text-gray-600\">Difficulty</p>\n                            <p class=\"text-2xl font-bold text-pink-600\">${difficultySelect.value.charAt(0).toUpperCase() + difficultySelect.value.slice(1)}</p>\n                        </div>\n                    </div>\n                </div>\n            `;\n\n            const confetti = document.createElement('div');\n            if (score >= 70) {\n                confetti.className = 'fixed inset-0 pointer-events-none';\n                confetti.innerHTML = Array(50).fill().map(() => `\n                    <div class=\"absolute animate-confetti\" style=\"\n                        left: ${Math.random() * 100}vw;\n                        animation-delay: ${Math.random() * 3}s;\n                        background: ${['#FF69B4', '#4B0082', '#9370DB'][Math.floor(Math.random() * 3)]};\n                    \"></div>\n                `).join('');\n                document.body.appendChild(confetti);\n            }\n        }\n    }\n\n    generateBtn.addEventListener('click', async () => {\n        const file = fileInput.files[0];\n        if (file) {\n            try {\n                progressBar.className = 'mb-8';\n                generateBtn.disabled = true;\n                const arrayBuffer = await file.arrayBuffer();\n                const quizQuestions = await extractTextAndGenerateQuiz(arrayBuffer);\n                displayQuiz(quizQuestions);\n                generateBtn.disabled = false;\n            } catch (error) {\n                console.error('Error generating quiz:', error);\n                alert('An error occurred while generating the quiz. Please try again.');\n                generateBtn.disabled = false;\n            }\n        } else {\n            const uploadLabel = fileInput.parentElement;\n            uploadLabel.classList.add('animate__animated', 'animate__shakeX');\n            setTimeout(() => {\n                uploadLabel.classList.remove('animate__animated', 'animate__shakeX');\n            }, 1000);\n        }\n    });\n\n    const style = document.createElement('style');\n    style.textContent = `\n        @keyframes confetti {\n            0% { transform: translateY(-10px) rotateZ(0); opacity: 1; }\n            100% { transform: translateY(100vh) rotateZ(720deg); opacity: 0; }\n        }\n        .animate-confetti {\n            width: 10px;\n            height: 10px;\n            opacity: 0;\n            animation: confetti 3s ease-in-out infinite;\n        }\n        @media print {\n            .fixed { display: none; }\n            .min-h-screen { min-height: auto; }\n            .shadow-2xl, .shadow-lg, .shadow-md { box-shadow: none; }\n        }\n    `;\n    document.head.appendChild(style);\n})();",
      "status": "[2]<br><span style=\"font-size:8px\">58ms<span></span></span>",
      "output": "",
      "type": "code"
    }
  ],
  "source": "https://github.com/gopi-suvanam/jsnb",
  "run_on_load": false
}